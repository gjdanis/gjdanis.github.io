---
layout: post
title: 2048 Python game and AI
published: false
---

[2048](http://gabrielecirulli.github.io/2048/) is a great game, and it's pretty easy to write a simplified clone of the game in the language of your choosing. Several [AI algorithms](http://stackoverflow.com/questions/22342854/what-is-the-optimal-algorithm-for-the-game-2048) also exist to play the game automatically, and I recently wondered how difficult it would be to develop something similar. 

### Full code and where weâ€™re going

By the end of this blog you'll have developed an artificial intelligence algorithm to a desktop clone of the game programatically. 

{% highlight python %}
>>>    0       2       0       0
       8       8       4       0
    1024       2       4       2
    2048       4      16       4
{% endhighlight %}

For reference, the final project can be found [here](https://github.com/gjdanis/2048). 

## Representing the board

Let's start with representation. Rather than creating a <code>Board</code> class, I decided to use Python lists to represent the game state. 

{% highlight python %}
class Game:
    def __init__(self):
        """ Initialize a 2048 game """
        b = [[0]*4 for i in range(4)]
        self.b = Game.spawn(b, 2)

    def spawn(b, k=1):
        """ 
        Add k random tiles to the board.
        Chance of 2 is 90%; chance of 4 is 10% 
        """
        rows, cols = list(range(4)), list(range(4))
        random.shuffle(rows)
        random.shuffle(cols)
        
        copy  = [[x for x in row] for row in b]
        dist  = [2]*9 + [4]
        count = 0
        for i,j in itertools.product(rows, rows):
            if copy[i][j] != 0: continue
            
            copy[i][j] = random.sample(dist, 1)[0]
            count += 1
            if count == k  : return copy
        raise Exception("shouldn't get here")       
{% endhighlight %}

You'll notice that the <code>spawn</code> function is <i>immutable</i>; we don't change the initial <code>b</code> variable defined in the constructor. Stateless design is appealing given that our AI would otherwise be constantly changing <code>b</code> to simulate the result of making a particular move (more on that later). The <code>Game</code> class isn't really OOP; it doesn't know how to "play itself" and requires that any client manage the board through functions like <code>spawn</code> that return new boards. 

The game is over when there are no empty tiles, and no tiles that can be merged. We can check whether or not the game is over in the "left-right" direction by looping over the cells of the board, and checking that no cells have neighbors with the same cell value, and further that all cells are nonempty. 

{% highlight python %}
def over(b):
    """ Returns true if the board is playable """
    def inner(b):
        for row in b:
            for x, y in zip(row[:-1], row[1:]):
                if x == y or x == 0 or y == 0:
                    return True
        return False
    return not inner(b) and not inner(zip(*b)) # "*" is called the "splat" operator
{% endhighlight %}

We also need to check the "up-down" direction. We can actually reuse the existing <code>inner</code> function by making the "columns" of the board "rows" in a new board. This new board is called the [transpose](https://en.wikipedia.org/wiki/Transpose), and can be computed concisely by combining the <code>zip</code> function with Python's <code>*</code> operator. Also referred to as the "splat" operator, <code>*</code> unpacks the board and extracts the four rows as lists. Since <code>zip</code> can take more than two iterables, the result of <code>zip</code>ping the unpacked rows is a collection of all the first elements in each row, followed by a collection of all the second elements in each row, etc. It's easy to see that the result is the transpose. 

## The merge algorithm 

Now for the merge. Let's start by writing a merge function that takes a board and shifts/merges everything right to left. Rather than do this in one fell swoop, I'm going to write a recursive inner function to do this row by row, and build up the return board sequentially. 

Why recursive? Rather than iteration, I think recursion provides a cleaner solution. If you think about it, we really only need to look at the first two elements in a row at a time. If they match, merge the result, advance past both of them, and recursively examine the rest of the row. If they don't, only skip the first element in the list, since the third element might match with the second element, and perform the same recursive process. 

Merging the entire board left is easy. For each row, we strip out the zeros and do a left merge on that row. We pad the merged row with the appropriate number of zeros, and append the merged row to our result board. 

{% highlight python %}
def merge(b):
    """ Returns a left merged board """
    
    def inner(row, a):
        """
        Helper for merge. If we're finished with the list,
        nothing to do; return the accumulator. Otherwise
        if we have more than one element, combine results of first
        with right if they match; skip over right and continue merge
        """
        
        if not row:
            return a
        x = row[0]
        if len(row) == 1:
            return inner(row[1:], a + [x])
        return inner(row[2:], a + [2*x]) if x == row[1] else inner(row[1:], a + [x])

    ret = []
    for row in b:
        merged = inner([x for x in row if x != 0], [])
        merged = merged + [0]*(len(row)-len(merged))
        ret.append(merged)
    return ret
{% endhighlight %}

There's a great [Haskell implementation](https://github.com/gregorulm/h2048/blob/master/h2048.hs) out there that does something similar using ["functional pattern matching"](http://stackoverflow.com/questions/2502354/what-is-pattern-matching-in-functional-languages), a common idiom in functional programming languages. Python doesn't support this exactly, but what we're doing with list splicing is somewhat analogous.  

With merge left taken care of, let's take a look at merge right. What we want to do is express a right merge in terms of what we've already done to merge the board left. This is easier than it sounds -- all we have to do is reverse each row, merge the reversed row, and take the reverse again to get back to the original representation. 

{% highlight python %}
def right(b):
    """ Returns a right merged board

    >>> Game.right(test)
    [[0, 0, 2, 8], [0, 2, 4, 8], [0, 0, 0, 4], [0, 0, 4, 4]]
    """

    def reverse(x):
        return list(reversed(x)) # want the actual list, not a generator object
    
    t = map(reverse, iter(b))
    return [reverse(x) for x in Game.merge(t)]
{% endhighlight %}

Merging up and down can now be expressed by again computing the transpose of the board, and calling <code>left</code> or <code>right</code> on the transposed board. 

{% highlight python %}
def up(b):
    """ Returns an upward merged board
        NOTE: zip(*t) is transpose
        
    >>> Game.up(test) 
    [[4, 8, 4, 8], [4, 2, 0, 2], [0, 0, 0, 4], [0, 0, 0, 0]]
    """

    t = Game.left(zip(*b))
    return [list(x) for x in zip(*t)]

def down(b):
    """ Returns an downward merged board
        NOTE: zip(*t) is transpose

    >>> Game.down(test)
    [[0, 0, 0, 0], [0, 0, 0, 8], [4, 8, 0, 2], [4, 2, 4, 4]]
    """
    
    t = Game.right(zip(*b))
    return [list(x) for x in zip(*t)]
{% endhighlight %}


## Developing an AI
Barring a pretty-print function, we're essentially done the <code>Game</code> class. Time to work on the AI.

### Adversarial search
Games like Tic-Tac-Toe can be played "perfectly" by an artificial "agent" because everything about the game is known to both players. To decide what move to play, the agent will typically play all possible moves, play all opponent response moves, and then score the resulting configurations with a "position fitness function". This process can be repeated recursively to deeper levels, resulting in a tree structure where each level alternates between the boards resulting from the agent's moves and the boards resulting from the adversary's response moves.

In [minimax](https://en.wikipedia.org/wiki/Minimax) search, the agent attempts to maximize the position fitness function and the adversary conversely seeks to minimize this function. and works great for what are called [zero sum games](https://en.wikipedia.org/wiki/Zero-sum_game), or games where one player's gains are the other player's losses. As good as this algorithm is[^fn-deep_blue], it's actually not a great strategy for 2048. This is because, in contrast to Chess or Tic-Tac-Toe, knowledge of the game is not perfect; the agent doesn't know the result of making a move as the tile spawns are random, and don't necessarily target the worst open position. 

Rather than the raw fitness score, what we want is to weight the fitness score for a given board by the probability that the board is generated next. If it is not the agent's turn to move, the fitness value we return will be the weighted average of all possible boards. In probability this weighted average is know as [expected value](https://en.wikipedia.org/wiki/Expected_value). Given a set of values and a set of "observation probabilities", the value one would expect is not the average of the set of values, but rather the average <i>weighted</i> by each value's chance of being observed. 

Not surprisingly, this algorithm is called [expectimax](https://en.wikipedia.org/wiki/Expectiminimax_tree) and closely resembles the minimax algorithm presented earlier. As we said before, we will evaluate each candidate move (left, right, up, or down) by simulating the game forward until some termination condition is met. The choice that maximizes the move's expected evaluation value (as oppose to the move that maximizes the evaluation value) wins. 

{% highlight python %}
def search(b, d, move=False):
    """
    Performs expectimax search on a given configuration to
    specified depth (d).

    Algorithm details:
       - if the AI needs to move, make each child move,
         recurse, return the maximum fitness value
       - if it is not the AI's turn, form all
         possible child spawns, and return their weighted average 
         as that node's evaluation
    """
    if d == 0 or (move and Game.over(b)):
        return fitness(b)

    alpha = fitness(b)
    if move:
        for _, child in Game.actions(b):
            alpha = max(alpha, search(child, d-1))
    else:
        alpha = 0
        zeros = [(i,j) for i,j in itertools.product(range(4), range(4)) if b[i][j] == 0]
        for i, j in zeros:
            c1 = [[x for x in row] for row in b]
            c2 = [[x for x in row] for row in b]
            c1[i][j] = 2
            c2[i][j] = 4
            alpha += .9*search(c1, d-1, True)/len(zeros) + \
                     .1*search(c2, d-1, True)/len(zeros)
    return alpha

# search and score the children of a given "root configuration" 
scores = [(action, search(child, 4)) for action ,child in Game.actions(b)]
{% endhighlight %}

### Evaluation function

We've discussed a general algorithm for determining what move to play: we simply simulate the game forward, playing every possible move on every possible board, and pick the move that gives the most favorable future configuration. All that's left is need to figure out a scoring heuristic to actually <i>drive</i> the search; something that mimics human strategy. The key to getting 2048 keep big tiles in a corner, and try to place smaller tiles around the big tile in descending order

Hopefully our search will be deep enough where we can anticipate and correctly weigh the decisions of 

## Final thoughts

Look at some of the highly optimized code for 

https://xkcd.com/1002/

[^fn-deep_blue]: IBM's [Deep Blue](https://en.wikipedia.org/wiki/Deep_Blue_(chess_computer)) Chess program used this strategy in a search to a depth of six to eight moves, sometimes even reaching a depth of twenty or more moves. 
